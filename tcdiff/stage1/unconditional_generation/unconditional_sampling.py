import argparse
import os
import pyrootutils
root = pyrootutils.setup_root(
    search_from=__file__,
    indicator=[".git", "pyproject.toml"],
    pythonpath=True,
    dotenv=True,
)
import torch as th
import torch.distributed as dist

from diffusion import dist_util, logger
from diffusion.script_util import (
    model_and_diffusion_defaults,
    create_model_and_diffusion,
    args_to_dict,
    add_dict_to_argparser,
)
from diffusion.image_datasets import load_data
from torchvision import utils
import math
import time


# added
def load_reference(data_dir, batch_size, image_size, class_cond=False):
    data = load_data(
        data_dir=data_dir,
        batch_size=batch_size,
        image_size=image_size,
        class_cond=class_cond,
        deterministic=True,
        random_flip=False,
    )
    for large_batch, model_kwargs in data:
        model_kwargs["ref_img"] = large_batch
        yield model_kwargs


def main():
    args = create_argparser().parse_args()

    # th.manual_seed(0)         # original
    th.manual_seed(args.seed)   # Bernardo

    dist_util.setup_dist()
    logger.configure(dir=args.save_dir)

    logger.log("creating model...")
    model, diffusion = create_model_and_diffusion(
        **args_to_dict(args, model_and_diffusion_defaults().keys())
    )
    model.load_state_dict(
        dist_util.load_state_dict(
            os.path.join(os.path.dirname(os.path.dirname(root)), 'pretrained_models/ffhq_10m.pt')
        , map_location="cpu")
    )
    model.to(dist_util.dev())
    if args.use_fp16:
        model.convert_to_fp16()
    model.eval()

    assert math.log(args.down_N, 2).is_integer()

    logger.log(f"\ncreating {args.num_samples} samples, seed={args.seed}...")
    count = 0
    while count * args.batch_size < args.num_samples:
        start_time = time.time()
        sample = diffusion.p_sample_loop(
            model,
            (args.batch_size, 3, args.image_size, args.image_size),
            clip_denoised=args.clip_denoised,
            model_kwargs={},
            range_t=args.range_t
        )
        end_time = time.time()
        total_elapsed_time = end_time - start_time
        logger.log('    Total time: %.2fs    Time per sample: %.2fs' % (total_elapsed_time, total_elapsed_time/args.batch_size))

        for i in range(args.batch_size):
            out_path = os.path.join(logger.get_dir(),
                                    f"{str(count * args.batch_size + i).zfill(5)}.png")
            logger.log(f'    Saving image: {out_path}')
            utils.save_image(
                sample[i].unsqueeze(0),
                out_path,
                nrow=1,
                normalize=True,
                value_range=(-1, 1),
            )

        count += 1
        logger.log(f"    created {count * args.batch_size}/{args.num_samples} samples")
        logger.log(f"-------------")

    dist.barrier()
    logger.log("\nsampling complete")


def create_argparser():
    defaults = dict(
        clip_denoised=True,
        num_samples=10000,
        batch_size=4,
        down_N=32,
        range_t=0,
        use_ddim=False,
        base_samples="",
        model_path="",
        save_dir="",
        save_latents=False,
        seed=0,   # Bernardo
    )
    defaults.update(model_and_diffusion_defaults())
    parser = argparse.ArgumentParser()
    add_dict_to_argparser(parser, defaults)
    return parser


if __name__ == "__main__":
    main()